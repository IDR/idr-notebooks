# -----------------------------------------------------------------------------
#  Copyright (C) 2018 University of Dundee. All rights reserved.
#
#
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
#  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
#
# ------------------------------------------------------------------------------

# This Jython script uses ImageJ to analyse particles, and saved the results
# locally in a CSV file.
# Use this script in the Scripting Dialog of Fiji (File > New > Script).
# Select Python as language in the Scripting Dialog.
# Error handling is omitted to ease the reading of the script but
# this should be added
# if used in production to make sure the services are closed
# Information can be found at
# https://docs.openmicroscopy.org/latest/omero/developers/Java.html


from java.lang import Long
from java.lang import String
from java.util import ArrayList

# OMERO Dependencies
from omero.gateway import Gateway
from omero.gateway import LoginCredentials
from omero.gateway import SecurityContext
from omero.gateway.facility import BrowseFacility
from omero.gateway.facility import MetadataFacility
from omero.gateway.model import ImageData
from omero.gateway.model import FileAnnotationData
from omero.gateway.model import MapAnnotationData
from omero.model import ImageI
from omero.log import SimpleLogger

from ij import IJ
from ij.plugin.frame import RoiManager
from ij.measure import ResultsTable

# Import required to save the results as CSV
import csv
import tempfile

# Setup
# =====

# OMERO Server details
HOST = "idr.openmicroscopy.org"
PORT = 4064
project_id = 51
USERNAME = "USERNAME"
PASSWORD = "PASSWORD"

MAP_KEY = "Channels"


def connect_to_omero():
    "Connect to OMERO. Returns a reference to the gateway"

    credentials = LoginCredentials()
    credentials.getServer().setHostname(HOST)
    credentials.getServer().setPort(PORT)
    credentials.getUser().setUsername(USERNAME.strip())
    credentials.getUser().setPassword(PASSWORD.strip())
    simpleLogger = SimpleLogger()
    gateway = Gateway(simpleLogger)

    user = gateway.connect(credentials)
    print user.getGroupId()
    return gateway, user


def get_datasets(gateway, ctx, project_id):
    "List all dataset's ids contained in a Project"

    browse = gateway.getFacility(BrowseFacility)
    ids = ArrayList(1)
    val = Long(project_id)
    ids.add(val)
    projects = browse.getProjects(ctx, ids)
    return projects[0].getDatasets()


def get_images(gateway, ctx, dataset_id):
    "List all images contained in a Dataset"

    browse = gateway.getFacility(BrowseFacility)

    ids = ArrayList(1)
    val = Long(dataset_id)
    ids.add(val)
    return browse.getImagesForDatasets(ctx, ids)


def get_channels_data(gateway, ctx, image_id):
    "List the channels data associated to the specified image"
    svc = gateway.getFacility(MetadataFacility)
    return svc.getChannelData(ctx, image_id)


def get_channel_wavelength(gateway, ctx, image_id, dataset_name):
    "Load the map annotations and find the channel's wavelength matching the dataset name"
    svc = gateway.getFacility(MetadataFacility)
    types = ArrayList(1)
    types.add(MapAnnotationData)
    data = ImageData(ImageI(image_id, False))
    annotations = svc.getAnnotations(ctx, data, types, None)
    # Iterate through annotation
    j = annotations.iterator()
    while j.hasNext():
        annotation = j.next()
        if annotation.getNameSpace() == FileAnnotationData.BULK_ANNOTATIONS_NS:
            named_values = annotation.getContent()
            i = named_values.iterator()
            while i.hasNext():
                nv = i.next()
                if nv.name == MAP_KEY:
                    channels = nv.value.split("; ")
                    for c, ch_name in enumerate(channels):
                        values = ch_name.split(":")
                        name = values[1]
                        if name in dataset_name:
                            return values[0]
                            break


def open_image_plus(HOST, USERNAME, PASSWORD, PORT, group_id, image_id):
    "Open the image using the Bio-Formats Importer"

    options = """location=[OMERO]
open=[omero:server=%s
user=%s
port=%s
pass=%s
groupID=%s
iid=%s]
 windowless=true """ % (HOST, USERNAME, PORT, PASSWORD, group_id, image_id)
    IJ.runPlugIn("loci.plugins.LociImporter", options)


def save_row(rt, table_rows, channel_index, dataset_name, image_id):
    "Create a summary table from the original table"
    # Remove the rows not corresponding to the specified channel
    to_delete = []
    ref = "c:" + str(channel_index)
    max_bounding_box = 0
    for i in range(0, rt.size()):
        label = rt.getStringValue("Label", i)
        if ref in label:
            w = rt.getStringValue("Width", i)
            h = rt.getStringValue("Height", i)
            area = float(w)*float(h)
            max_bounding_box = max(area, max_bounding_box)

    # Rename the table so we can read the summary table
    IJ.renameResults("Results")
    rt = ResultsTable.getResultsTable()
    for i in range(0, rt.size()):
        value = rt.getStringValue("Slice", i)
        if not value.startswith(ref):
            to_delete.append(i)
    # Delete the rows we do not need
    for index, value in enumerate(to_delete):
        v = value-index
        rt.deleteRow(v)
    rt.updateResults()
    # Insert values in summary table
    for i in range(0, rt.size()):
        rt.setValue("Dataset", i, dataset_name)
        rt.setValue("Bounding_Box", i, max_bounding_box)
    # Create a tmp file and save the result
    headings = rt.getHeadings()
    row = []
    for j in range(0, rt.size()):
        for i in range(0, len(headings)):
            heading = rt.getColumnHeading(i)
            if heading == "Slice" or heading == "Dataset":
                row.append(rt.getStringValue(i, j))
            else:
                row.append(rt.getValue(i, j))
    row.append(image_id)
    table_rows.append(row)
    return headings


def create_table_columns(headings):
    "Create the table headings from the ImageJ results table"
    size = len(headings)
    table_columns = [String]*(size+1)
    # populate the headings
    for h in range(0, size):
        table_columns[h] = headings[h]

    table_columns[size] = "Image ID"
    return table_columns


def save_summary_as_csv(file, rows, columns):
    "Save the summary locally as a CSV"
    with open(file.name, 'wb') as master:
        master_csv = csv.writer(master)
        headers = []
        for i in range(0, len(table_columns)):
            headers.append(table_columns[i])
        master_csv.writerow(headers)

        for i in range(0, len(table_rows)):
            row = table_rows[i]
            line = []
            size = len(row)
            for j in range(0, size):
                line.append(row[j])
            master_csv.writerow(line)


# Connect
gateway, user = connect_to_omero()
group_id = user.getGroupId()
ctx = SecurityContext(group_id)
exp = gateway.getLoggedInUser()
exp_id = exp.getId()

table_rows = []
table_columns = None

# get all the dataset_ids in an project
datasets = get_datasets(gateway, ctx, project_id)

# Close all the windows
IJ.run("Close All")
j = datasets.iterator()
while j.hasNext():
    d = j.next()
    name = d.getName()
    # for each dataset load the images
    # get all images_ids in the dataset
    images = get_images(gateway, ctx, d.getId())
    for image in images:
        if image.getName().endswith(".tif"):
            continue
        id = image.getId()
        channel_index = 1
        # Find the index of the channel matching the dataset name as a string
        channel_wavelength = get_channel_wavelength(gateway, ctx, id, name)
        channels = get_channels_data(gateway, ctx, id)
        i = channels.iterator()
        while i.hasNext():
            channel = i.next()
            em = channel.getEmissionWavelength(None)
            if em is not None:
                v = str(int(em.getValue()))
                if channel_wavelength == v:
                    channel_index = channel.getIndex()+1
                    print "Found index: "+str(channel_index)
                    break

        open_image_plus(HOST, USERNAME, PASSWORD, PORT, group_id, id)
        imp = IJ.getImage()
        # Some analysis which creates ROI's and Results Table
        IJ.run("8-bit")
        IJ.run(imp, "Auto Threshold", "method=MaxEntropy stack")
        IJ.run(imp, "Analyze Particles...", "size=10-Infinity pixel display clear add stack summarize")
        IJ.run("Set Measurements...", "area mean standard modal min centroid center perimeter bounding feret's summarize stack display redirect=None decimal=3")

        rm = RoiManager.getInstance()
        rm.runCommand(imp, "Measure")
        rt = ResultsTable.getResultsTable()
        print "creating summary results for image ID " + str(id)
        headings = save_row(rt, table_rows, channel_index, name, id)
        if (table_columns is None):
            table_columns = create_table_columns(headings)

        # Close the various components
        IJ.run("Close All")

# Close the connection
gateway.disconnect()

tmp_dir = tempfile.gettempdir()
file = tempfile.TemporaryFile(mode='wb', prefix='idr0021_merged_results_', suffix='.csv', dir=tmp_dir)
save_summary_as_csv(file, table_rows, table_columns)

print "processing done"
